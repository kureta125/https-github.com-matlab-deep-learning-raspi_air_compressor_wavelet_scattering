<学習に使用するデータ>
学習には元の音声データを使用せず、実際のデモ時の状況でマイクにより音質が変化することを考慮し、
一旦スピーカーから出力し、Raspberry-Piのマイク入力を再録音したものを使用。
Raspberry-Pi上で再生&録音し直しているが、タイムラグが発生して
録音データの最初0.1秒ほどが無音状態となるため、最初のサンプルを捨てて中間のデータを学習に使用
このオフセットサンプル数を変更してデータを水増しして、採音タイミングの変動に強いネットワークを学習させる
(ハードウエア実行時も精度は向上するが、なぜかNRVをLIVと誤判別する割合が顕著に増加)

<学習データの再生&録音について>
デモ実行時と同じく、winで再生してRaspiで採音するのが理想的だが、現状はRaspberry-Pi上で再生&録音している
winでは音声システムが古いアーキテクチャの複合で、バッチ処理でファイル名を指定して再生することが難しく、
またRaspberry-Pi側と同期させて駆動することが難しいため。
スピーカーの駆動主体は録音時はRaspberry-Pi デモ時はWindowsと相違するが、
マイク端子に接続するアナログマイクではなく、USBで接続するデジタルマイクとすると、ドライバの差異による音質変化は無視できそう。

<Linux上での採音用シェルスクリプト>
Linux側ではALSAのCLIを利用してシェルスクリプトを組んでフォルダ毎に再生&録音することができる(サンプリング周波数やデータ長も指定)
その際、先に録音をバックグランド実行開始し、その後再生を実行すると、上記無音期間は0.1秒ほどで安定
逆に先に再生をバックグランド実行開始し、その後録音を実行すると、上記無音期間は0.05-0.35秒ほどでばらつく
スピーカーとマイクの音量設定は、シェルスクリプトで指定しておく。
alsa_rw.sh

<スピーカードライバの相違>
win-Raspi間でドライバの差異による音質変化は無視できそうだが、以下には留意する。
Windowsドライバの"出力の設定"-"オーディオの強化"では"デバイスの規定の効果"はオフに設定する。
また、ALSAでのスピーカーボリュームの設定とWindowsドライバでのボリューム設定はリンクしていない(ALSA 50％=win 65%?)
録音時のマイクとスピーカーの位置は、デモ実施時と同等の位置関係とし、外部の音を遮断するための覆いなどは設けない(音が籠る)